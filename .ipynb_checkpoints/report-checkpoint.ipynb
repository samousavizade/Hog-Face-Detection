{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"margin: 20px; text-align: center; font-size: 30px;\"> Compute Vision HW4</div>\n",
    "<div style=\"margin: 20px; text-align: center; font-size: 30px;\">Face Detection Using HOG</div>\n",
    "<br><br>\n",
    "<div style=\"margin: 10px; text-align: right; font-size: 20px;\">\n",
    " S.Alireza Mousavizade\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; margin:20px\">\n",
    "\n",
    "### - آماده سازی مجموعه داده های مورد نیاز:\n",
    "#### مجموعه داده های تصویر مثبت :\n",
    "\n",
    "#### _LFW Data Set_\n",
    "#### http://vis-www.cs.umass.edu/lfw\n",
    "\n",
    "\n",
    "***\n",
    "#### مجموعه داده های تصویر منفی :\n",
    "\n",
    "#### _Caltech 256 Data Set_ (تصاویر حاوی چهره از این دیتاست حذف شده است.)\n",
    "#### http://www.vision.caltech.edu/Image_Datasets/Caltech256/\n",
    "\n",
    "## پروسه الگوریتم:\n",
    "</div>\n",
    "\n",
    "<div style=\"direction:rtl; margin:20px\">\n",
    "\n",
    "### 0- ساختن شی HOGFaceDetector با مقادیر آدرس داده های مثبت و منفی + آدرس های مربوط به بازیابی:\n",
    "#### تابع init (سازنده این class) این عمل را انجام میدهد:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-1-3aba468b91c8>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-3aba468b91c8>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    self.positive_train_dir_path = positive_train_dir_path\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def __init__(self,\n",
    "         positive_train_dir_path,\n",
    "         negative_train_dir_path,\n",
    "         winSize,\n",
    "         train_set_path,\n",
    "         validation_set_path,\n",
    "         test_set_path,\n",
    "         train_hog_features_path,\n",
    "         validation_hog_features_path,\n",
    "         test_hog_features_path,\n",
    "         svm_model_path,\n",
    "         y_predict_path):\n",
    "\n",
    "self.positive_train_dir_path = positive_train_dir_path\n",
    "self.negative_train_dir_path = negative_train_dir_path\n",
    "\n",
    "self.X_train, self.Y_train = None, None\n",
    "self.X_validation, self.Y_validation = None, None\n",
    "self.X_test, self.Y_test = None, None\n",
    "\n",
    "self.hog_object = None\n",
    "self.winSize = winSize\n",
    "\n",
    "self.train_HOG_features = None\n",
    "self.validation_HOG_features = None\n",
    "self.test_HOG_features = None\n",
    "\n",
    "self.Y_test_predicted = None\n",
    "\n",
    "self.scalar = None\n",
    "self.svm_kernel = ''\n",
    "\n",
    "self.classifier_model = None\n",
    "\n",
    "self.average_precision_recall_score = 0\n",
    "\n",
    "self.train_set_path = train_set_path\n",
    "self.validation_set_path = validation_set_path\n",
    "self.test_set_path = test_set_path\n",
    "self.train_hog_features_path = train_hog_features_path\n",
    "self.validation_hog_features_path = validation_hog_features_path\n",
    "self.test_hog_features_path = test_hog_features_path\n",
    "self.svm_model_path = svm_model_path\n",
    "self.y_predict_path = y_predict_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; margin:20px\">\n",
    "\n",
    "### 1- خواندن تصاویر و تقسیم بندی به داده های آموزش، اعتبارسنجی و آزمون:\n",
    "#### تابع initialize از شی HOGFaceDetector این عمل را انجام میدهد:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def initialize(self):\n",
    "    # p: Positive / n: Negative\n",
    "\n",
    "    retriever1 = Retriever(self.train_set_path)\n",
    "    retriever2 = Retriever(self.validation_set_path)\n",
    "    retriever3 = Retriever(self.test_set_path)\n",
    "\n",
    "    try:\n",
    "        self.X_train, self.Y_train = retriever1.retrieve()\n",
    "        self.X_validation, self.Y_validation = retriever2.retrieve()\n",
    "        self.X_test, self.Y_test = retriever3.retrieve()\n",
    "\n",
    "    except:\n",
    "        p_X, p_Y, positive_patches_size = self.retrieve_samples_of(self.positive_train_dir_path,\n",
    "                                                                   label=1)\n",
    "\n",
    "        n_X, n_Y, negative_patches_size = self.retrieve_samples_of(self.negative_train_dir_path,\n",
    "                                                                   label=0)\n",
    "\n",
    "        train_size = 20000 // 2\n",
    "        validation_size = 2000 // 2\n",
    "        test_size = 2000 // 2\n",
    "        # total_size = train_size + validation_size + test_size\n",
    "\n",
    "        p_X_train, p_Y_train, \\\n",
    "        p_X_validation, p_Y_validation, \\\n",
    "        p_X_test, p_Y_test = HOGFaceDetector.train_validation_test_split(p_X, p_Y,\n",
    "                                                                         train_size,\n",
    "                                                                         validation_size,\n",
    "                                                                         test_size)\n",
    "\n",
    "        n_X_train, n_Y_train, \\\n",
    "        n_X_validation, n_Y_validation, \\\n",
    "        n_X_test, n_Y_test = HOGFaceDetector.train_validation_test_split(n_X, n_Y,\n",
    "                                                                         train_size,\n",
    "                                                                         validation_size,\n",
    "                                                                         test_size)\n",
    "\n",
    "        self.X_train, self.Y_train = p_X_train + n_X_train, p_Y_train + n_Y_train\n",
    "        retriever1.save([self.X_train, self.Y_train])\n",
    "\n",
    "        self.X_validation, self.Y_validation = p_X_validation + n_X_validation, p_Y_validation + n_Y_validation\n",
    "        retriever2.save([self.X_validation, self.Y_validation])\n",
    "\n",
    "        self.X_test, self.Y_test = p_X_test + n_X_test, p_Y_test + n_Y_test\n",
    "        retriever3.save([self.X_test, self.Y_test])\n",
    "\n",
    "    logging.info('HOGFaceDetector object initialized ... ')\n",
    "\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; margin:20px\">\n",
    "\n",
    "\n",
    "\n",
    "### 2- استخراج بردار های ویژگی HOG از تصاویر:\n",
    "#### تابع extract_features از شی HOGFaceDetector این عمل را انجام میدهد:\n",
    "\n",
    "##### برای استخراج بردار های ویژگی از کتابخانه OpenCV استفاده است که مفادیر پارامترها به صورت زیر است:\n",
    "\n",
    "| Parameter | Value |\n",
    "| - | - |\n",
    "| winSize | 128, 128 |\n",
    "| blockSize | (32, 32) |\n",
    "| blockStride | (16, 16) |\n",
    "| cellSize | (16, 16) |\n",
    "| nbins | 9 |\n",
    "| derivAperture | 1 |\n",
    "| winSigma | -1 |.\n",
    "| histogramNormType | 0 |\n",
    "| L2HysThreshold | 0.2\n",
    "| gammaCorrection | 1 |\n",
    "| nlevels | 64 |\n",
    "| signedGradient | True |\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def extract_HOG_features(self):\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    self.hog_object = HOGFaceDetector.HOG(self.winSize)\n",
    "\n",
    "    retriever1 = Retriever(self.train_hog_features_path)\n",
    "    retriever2 = Retriever(self.validation_hog_features_path)\n",
    "    retriever3 = Retriever(self.test_hog_features_path)\n",
    "\n",
    "    try:\n",
    "        self.train_HOG_features = retriever1.retrieve()\n",
    "        self.validation_HOG_features = retriever2.retrieve()\n",
    "        self.test_HOG_features = retriever3.retrieve()\n",
    "\n",
    "        print('Retrieved from file ...')\n",
    "    except:\n",
    "        # for image in self.X_train:\n",
    "        #     histogram_equalization(image)\n",
    "\n",
    "        features_ = [self.hog_object.extract_features(image) for image in self.X_train]\n",
    "        self.train_HOG_features = features_\n",
    "        retriever1.save(features_)\n",
    "\n",
    "        features_ = [self.hog_object.extract_features(image) for image in self.X_validation]\n",
    "\n",
    "        self.validation_HOG_features = features_\n",
    "        retriever2.save(features_)\n",
    "\n",
    "        features_ = [self.hog_object.extract_features(image) for image in self.X_test]\n",
    "        self.test_HOG_features = features_\n",
    "        retriever3.save(features_)\n",
    "\n",
    "    # clear space\n",
    "\n",
    "    del self.X_train\n",
    "    del self.X_validation\n",
    "    del self.X_test\n",
    "    gc.collect()\n",
    "    time.sleep(5)\n",
    "\n",
    "    logging.info('feature descriptors of train and test set extracted ... ')\n",
    "\n",
    "    return self\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; margin:20px\">\n",
    "\n",
    "\n",
    "\n",
    "### 3- آموزش مدل SVM به کمک بردارهای ویژگی بدست آمده:\n",
    "#### تابع extract_features از شی HOGFaceDetector این عمل را انجام میدهد:\n",
    "\n",
    "##### برای استخراج بردار های ویژگی از کتابخانه OpenCV استفاده است که مفادیر پارامترها به صورت زیر است:\n",
    "\n",
    "| Parameter | Value |\n",
    "| - | - |\n",
    "| Kernle | Linear |\n",
    "| C | 0.01\n",
    "\n",
    "#### مقادیر C برای مقادیر مختلف $10 ^ i : i = .0001, .001, .01, .1, 10 $\n",
    " #### بررسی شده است. همچنین به این علت که هسته خطی نسبت به RBF و Poly\n",
    " #### در حالات کمتری Overfit میشود، از این هسته استفاده شده است.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def classify_svm(self, kernel):\n",
    "\n",
    "    self.scalar = StandardScaler()\n",
    "    self.train_HOG_features = self.scalar.fit_transform(self.train_HOG_features)\n",
    "    self.validation_HOG_features = self.scalar.transform(self.validation_HOG_features)\n",
    "    self.test_HOG_features = self.scalar.transform(self.test_HOG_features)\n",
    "\n",
    "    gc.collect()\n",
    "\n",
    "    retriever = Retriever(self.svm_model_path)\n",
    "\n",
    "    try:\n",
    "        self.classifier_model = retriever.load()\n",
    "        print('Retrieved from file ...')\n",
    "    except:\n",
    "\n",
    "        # construct classifier_model model\n",
    "        svc = SVC(kernel=kernel,\n",
    "                  C=0.01,\n",
    "                  max_iter=-1,\n",
    "                  probability=True,\n",
    "                  cache_size=600, )\n",
    "\n",
    "        # # estimate parameters\n",
    "        # c_parameter = [i * 0.1 for i in range(3, 18)]\n",
    "        # c_parameter = [1]\n",
    "        # gamma_parameter = [10 ** i for i in range(-5, 1)]\n",
    "        # gamma_parameter = [10 ** -4]\n",
    "        #\n",
    "        # parameters = [{'kernel': [kernel], 'C': c_parameter]\n",
    "        #\n",
    "        # grid_search = GridSearchCV(scoring='accuracy',\n",
    "        #                            estimator=svc,\n",
    "        #                            param_grid=parameters)\n",
    "        #\n",
    "        # # fit model to estimate\n",
    "        # grid_search = grid_search.fit(self.validation_HOG_features, self.Y_validation)\n",
    "\n",
    "        # train classifier\n",
    "        self.classifier_model.fit(self.train_HOG_features,\n",
    "                                  self.Y_train)\n",
    "\n",
    "        retriever.save(self.classifier_model)\n",
    "\n",
    "    # self.classifier_model = grid_search.best_estimator_\n",
    "\n",
    "    # predict test image labels\n",
    "    self.Y_test_predicted = self.classifier_model.predict(self.test_HOG_features)\n",
    "\n",
    "    logging.info('test set classified ')\n",
    "\n",
    "    self.compute_metrics()\n",
    "    logging.info('metrics computed and saved ')\n",
    "\n",
    "    # clear space\n",
    "    del self.train_HOG_features\n",
    "    del self.validation_HOG_features\n",
    "    del self.test_HOG_features\n",
    "    gc.collect()\n",
    "    time.sleep(5)\n",
    "\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; margin:20px\">\n",
    "\n",
    "\n",
    "\n",
    "### که نتایج حاصل شده به صورت زیر است:\n",
    "#### تابع extract_features از شی HOGFaceDetector این عمل را انجام میدهد:\n",
    "\n",
    "##### برای استخراج بردار های ویژگی از کتابخانه OpenCV استفاده است که مفادیر پارامترها به صورت زیر است:\n",
    "\n",
    "| Parameter | Value |\n",
    "| - | - |\n",
    "| Accuracy | 0.998 |\n",
    "| C | 0.01\n",
    "\n",
    "![ROC Curve](res1.jpg)\n",
    "\n",
    "![P-R Curve](res2.jpg)\n",
    "\n",
    "#### که تابع compute_metrics این عمل را انجام میدهد:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(self):\n",
    "    y_score = self.classifier_model.decision_function(self.test_HOG_features)\n",
    "\n",
    "    av_precision_recall_score = average_precision_score(self.Y_test,\n",
    "                                                        y_score)\n",
    "\n",
    "    logging.info('Average precision-recall score: {0:0.2f}'.format(av_precision_recall_score))\n",
    "\n",
    "    display = plot_precision_recall_curve(self.classifier_model,\n",
    "                                          self.test_HOG_features,\n",
    "                                          self.Y_test)\n",
    "\n",
    "    display.ax_.set_title('Precision Recall Curve: AP = ' + str(av_precision_recall_score))\n",
    "    plt.savefig('res2.jpg', format='jpg', dpi=400)\n",
    "    logging.info('Average Precision-Recall Score: {0:0.2f}'.format(av_precision_recall_score))\n",
    "\n",
    "    roc_area_under_curve = roc_auc_score(self.Y_test,\n",
    "                                         y_score)\n",
    "\n",
    "    display = plot_roc_curve(self.classifier_model,\n",
    "                             self.test_HOG_features,\n",
    "                             self.Y_test)\n",
    "\n",
    "    display.ax_.set_title('ROC Curve: AUC = ' + str(roc_area_under_curve))\n",
    "    plt.savefig('res1.jpg', format='jpg', dpi=400)\n",
    "    logging.info('ROC Area Under Curve: {0:0.2f}'.format(roc_area_under_curve))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; margin:20px\">\n",
    "\n",
    "### 4- Sliding Window:\n",
    "#### تابع FaceDetector این عمل را انجام میدهد:\n",
    "\n",
    "##### برای Non Maximum Suppression از کتابخانه TensorFlow استفاده است.\n",
    "##### همچنین Sliding Window برای اسکیل های مختلف انجام میشود.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def FaceDetector(test_image, patch_h, patch_w, hog_face_detector: HOGFaceDetector):\n",
    "    # equalized_histogram_test_image = histogram_equalization(test_image, copy=True)\n",
    "    padding = 50\n",
    "    equalized_histogram_test_image = add_padding(test_image, padding=padding)\n",
    "    test_image = add_padding(test_image, padding=padding)\n",
    "\n",
    "    hog: HOGFaceDetector.HOG = hog_face_detector.hog_object\n",
    "    scalar: StandardScaler = hog_face_detector.scalar\n",
    "    classifier_model: SVC = hog_face_detector.classifier_model\n",
    "\n",
    "    equalized_histogram_test_image = cv2.cvtColor(equalized_histogram_test_image, cv2.COLOR_BGR2RGB)\n",
    "    image_height, image_width, _ = equalized_histogram_test_image.shape\n",
    "\n",
    "    scales = [.05 * i for i in range(8, 20)]\n",
    "\n",
    "    import tensorflow as tf\n",
    "    step = 1\n",
    "    picked_patches = []\n",
    "    score_thresh = .995\n",
    "    for scale in scales:\n",
    "        scaled_test_image = cv2.resize(equalized_histogram_test_image, dsize=(0, 0), fx=scale, fy=scale)\n",
    "        H, W, _ = scaled_test_image.shape\n",
    "\n",
    "        print('scale: ', str(scale))\n",
    "        total_numbers = (H - patch_h) * (W - patch_w)\n",
    "\n",
    "        patches = np.zeros((total_numbers, 6))\n",
    "        index = 0\n",
    "        for y in range(0, H - patch_h, step):\n",
    "            for x in range(0, W - patch_w, step):\n",
    "                part = scaled_test_image[y:y + patch_h, x:x + patch_w]\n",
    "                feature_descriptors = hog.extract_features(part).reshape(1, -1)\n",
    "                normal_feature_descriptors = scalar.transform(feature_descriptors)\n",
    "                probability = classifier_model._predict_proba(normal_feature_descriptors)\n",
    "                x1, y1, x2, y2 = x, y, x + patch_w, y + patch_h\n",
    "\n",
    "                patches[index, :] = [probability[0, 1], y1, x1, y2, x2, scale]\n",
    "                index += 1\n",
    "\n",
    "        patches = patches[patches[:, 0] > score_thresh]\n",
    "        picked_patches.append(patches)\n",
    "\n",
    "    picked_patches = np.vstack(picked_patches)\n",
    "\n",
    "    indices = tf.image.non_max_suppression(picked_patches[:, 1:5],\n",
    "                                           picked_patches[:, 0],\n",
    "                                           max_output_size=50,\n",
    "                                           iou_threshold=.4,\n",
    "                                           score_threshold=score_thresh).numpy()\n",
    "\n",
    "    picked_patches = picked_patches[indices]\n",
    "\n",
    "    indices = np.ones_like(indices)\n",
    "\n",
    "    n = len(picked_patches)\n",
    "    for i1 in range(n):\n",
    "        for i2 in range(i1 - 1):\n",
    "            p1 = picked_patches[i1]\n",
    "            p2 = picked_patches[i2]\n",
    "            y1_a, x1_a, y2_a, x2_a, scale_a = p1[1:]\n",
    "            y1_a, x1_a, y2_a, x2_a = y1_a // scale_a, x1_a // scale_a, y2_a // scale_a, x2_a // scale_a\n",
    "\n",
    "            y1_b, x1_b, y2_b, x2_b, scale_b = p2[1:]\n",
    "            y1_b, x1_b, y2_b, x2_b = y1_b // scale_b, x1_b // scale_b, y2_b // scale_b, x2_b // scale_b\n",
    "\n",
    "            S1 = (x2_a - x1_a) * (y2_a - y1_a)\n",
    "            S1 = int(S1)\n",
    "\n",
    "            S2 = (x2_b - x1_b) * (y2_b - y1_b)\n",
    "            S2 = int(S2)\n",
    "\n",
    "            overlap = max(0, min(x2_a, x2_b) - max(x1_a, x1_b)) * max(0, min(y2_a, y2_b) - max(y1_a, y1_b))\n",
    "            overlap = int(overlap)\n",
    "\n",
    "            union = S1 + S2 - overlap\n",
    "            # union = overlap\n",
    "            if union == S1:\n",
    "                indices[i1] = 0\n",
    "\n",
    "            elif union == S2:\n",
    "                indices[i2] = 0\n",
    "\n",
    "    indices = np.where(indices == 1)\n",
    "\n",
    "    final_patches = picked_patches[indices]\n",
    "\n",
    "    for index, patch in enumerate(final_patches):\n",
    "        probability, y1, x1, y2, x2, scale = patch\n",
    "        y, x, h, w = y1, x1, y2 - y1, x2 - x1\n",
    "        y, x, h, w = y // scale, x // scale, h // scale, w // scale\n",
    "        y, x, h, w = int(y), int(x), int(h), int(w),\n",
    "        y, x = y, x\n",
    "        y1, x1, y2, x2 = y, x, y + h, x + w\n",
    "        color = (0, 255, 0)\n",
    "        test_image = cv2.rectangle(test_image, (x1, y1), (x2, y2), color=color, thickness=2)\n",
    "\n",
    "        color = (255, 255, 255)\n",
    "        test_image = cv2.putText(test_image,\n",
    "                                 'P: ' + str(round(probability, 3)) + ', Scale: ' + str(scale),\n",
    "                                 (x1, y1 - 5),\n",
    "                                 cv2.FONT_HERSHEY_PLAIN,\n",
    "                                 .7,\n",
    "                                 color,\n",
    "                                 thickness=1,\n",
    "                                 lineType=2)\n",
    "\n",
    "    cv2.imshow('f', test_image)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    return test_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl; margin:20px\">\n",
    "\n",
    "#####  که نتایج به صورت زیر است:\n",
    "\n",
    "![Result 04](res4.jpg)\n",
    "\n",
    "![Result 05](res5.jpg)\n",
    "\n",
    "![Result 06](res6.jpg)\n",
    "\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (face_detection)",
   "language": "python",
   "name": "pycharm-c0c56c48"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
